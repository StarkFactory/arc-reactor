package com.arc.reactor.promptlab.model

import java.time.Instant
import java.util.UUID

// ── Experiment Lifecycle ──

/** Experiment status lifecycle */
enum class ExperimentStatus {
    PENDING, RUNNING, COMPLETED, FAILED, CANCELLED
}

/**
 * Top-level experiment container.
 *
 * An experiment compares a baseline prompt version against one or more
 * candidate versions using a set of test queries evaluated through
 * the 3-tier evaluation pipeline.
 */
data class Experiment(
    val id: String = UUID.randomUUID().toString(),
    val name: String,
    val description: String = "",
    val templateId: String,
    val baselineVersionId: String,
    val candidateVersionIds: List<String>,
    val testQueries: List<TestQuery>,
    val evaluationConfig: EvaluationConfig = EvaluationConfig(),
    val model: String? = null,
    val judgeModel: String? = null,
    val temperature: Double = 0.3,
    val repetitions: Int = 1,
    val autoGenerated: Boolean = false,
    val status: ExperimentStatus = ExperimentStatus.PENDING,
    val createdBy: String = "system",
    val createdAt: Instant = Instant.now(),
    val startedAt: Instant? = null,
    val completedAt: Instant? = null,
    val errorMessage: String? = null
)

/** Test query for experiment evaluation */
data class TestQuery(
    val query: String,
    val intent: String? = null,
    val domain: String? = null,
    val expectedBehavior: String? = null,
    val tags: List<String> = emptyList()
)

/** Evaluation pipeline configuration */
data class EvaluationConfig(
    val structuralEnabled: Boolean = true,
    val rulesEnabled: Boolean = true,
    val llmJudgeEnabled: Boolean = true,
    val llmJudgeBudgetTokens: Int = 100_000,
    val customRubric: String? = null
)

// ── Trial Results ──

/**
 * Single trial result — one prompt version x one query x one repetition.
 */
data class Trial(
    val id: String = UUID.randomUUID().toString(),
    val experimentId: String,
    val promptVersionId: String,
    val promptVersionNumber: Int,
    val testQuery: TestQuery,
    val repetitionIndex: Int = 0,
    val response: String? = null,
    val success: Boolean = false,
    val errorMessage: String? = null,
    val toolsUsed: List<String> = emptyList(),
    val tokenUsage: TokenUsageSummary? = null,
    val durationMs: Long = 0,
    val evaluations: List<EvaluationResult> = emptyList(),
    val executedAt: Instant = Instant.now()
)

/** Aggregated token usage for a single trial */
data class TokenUsageSummary(
    val promptTokens: Int,
    val completionTokens: Int,
    val totalTokens: Int = promptTokens + completionTokens
)

/** Result from a single evaluation tier */
data class EvaluationResult(
    val tier: EvaluationTier,
    val passed: Boolean,
    val score: Double,
    val reason: String,
    val evaluatorName: String = tier.name
)

// ── Report Models ──

/** Experiment comparison report */
data class ExperimentReport(
    val experimentId: String,
    val experimentName: String,
    val generatedAt: Instant = Instant.now(),
    val totalTrials: Int,
    val versionSummaries: List<VersionSummary>,
    val queryComparisons: List<QueryComparison>,
    val recommendation: Recommendation
)

/** Per-version aggregate statistics */
data class VersionSummary(
    val versionId: String,
    val versionNumber: Int,
    val isBaseline: Boolean,
    val totalTrials: Int,
    val passCount: Int,
    val passRate: Double,
    val avgScore: Double,
    val avgDurationMs: Double,
    val totalTokens: Int,
    val tierBreakdown: Map<EvaluationTier, TierStats>,
    val toolUsageFrequency: Map<String, Int>,
    val errorRate: Double
)

/** Pass/fail statistics for a single evaluation tier */
data class TierStats(
    val passCount: Int,
    val failCount: Int,
    val passRate: Double,
    val avgScore: Double
)

/** Side-by-side comparison of versions for a single query */
data class QueryComparison(
    val query: TestQuery,
    val versionResults: List<QueryVersionResult>
)

/** A single version's result for a specific query */
data class QueryVersionResult(
    val versionId: String,
    val versionNumber: Int,
    val response: String?,
    val passed: Boolean,
    val score: Double,
    val durationMs: Long,
    val evaluationDetails: List<EvaluationResult>
)

/** Report recommendation */
data class Recommendation(
    val bestVersionId: String,
    val bestVersionNumber: Int,
    val confidence: RecommendationConfidence,
    val reasoning: String,
    val improvements: List<String> = emptyList(),
    val warnings: List<String> = emptyList()
)

/** Recommendation confidence based on pass rate delta */
enum class RecommendationConfidence {
    /** >10% pass rate difference */
    HIGH,

    /** 5-10% pass rate difference */
    MEDIUM,

    /** <5% difference or insufficient data */
    LOW
}

// ── Feedback Analysis Models ──

/** Result of analyzing negative feedback for a prompt template */
data class FeedbackAnalysis(
    val totalFeedback: Int,
    val negativeCount: Int,
    val weaknesses: List<PromptWeakness>,
    val sampleQueries: List<TestQuery>,
    val analyzedAt: Instant = Instant.now()
)

/** Identified weakness in the current prompt */
data class PromptWeakness(
    val category: String,
    val description: String,
    val frequency: Int,
    val exampleQueries: List<String>
)
